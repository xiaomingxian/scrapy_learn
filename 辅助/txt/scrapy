将python下载的工具添加到全局

将此路径添加到环境变量 ：E:\python3.6\Scripts
#--------------------------- 安装问题 --------------------------
一般提示重复的，删除 E:\python3.6\Lib\site-packages 下的同名-info文件即可
#--------------------------  更新pip  --------------------------
python -m pip install --upgrade pip
得删除其他的pip版本  pip包得留下

pip --default-timeout=100 install -U selenium
#---------------------------
环境搭建：windows

     这里去官网上下载Twisted文件：https://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted
	    cp后面是python版本号，根据你自己系统安装的python版本进行相应下载即可。
                Twisted-18.9.0-cp36-cp36m-win_amd64.whl
        进入Twisted-18.9.0-cp36-cp36m-win_amd64.whl目录执行：
        pip install Twisted-18.9.0-cp36-cp36m-win_amd64.whl

        pip install scrapy

#----------- 忽略
		下载 ： virtualenv-15.1.0-py2.py3-none-any.whl
		pip install --upgrade twisted pypiwin32

#---------------------爬虫项目
	创建
		scrapy startproject xxx
		scrapy genspider my_spider baidu.com[爬虫范围]
	启动爬虫
		scrapy crawl my_sppider[爬虫名]
		scrapy crawl my_sppider[爬虫名] -o  文件名 #输出数据到指定文件  csv/json/xml
		报错：ModuleNotFoundError: No module named 'win32api'
		pip install pywin32 或者以下方式
            https://sourceforge.net/projects/pywin32/files/pywin32/
             下build220:
              下载   pywin32-220.win-amd64-py3.6   3.6
                    pywin32-220.win-amd64-py3.7   3.7


查看爬虫数量 scrapy list


#模拟发送请求
scrapy shell 'http.....'


response---相关
response.Selectors().xpath() -->简写为.xpath()
...                 .css()
...                 .re()


请求去重思想：每一个请求过来的时候会留下请求的指纹[特征码]，会保留在scrapy的内存
            请求过来的时候会提取特征码与原来的进行比对，如果在特征码库中有这个特征码，就不会将它加入到请求队列里



xpath多规则 用 or/|连接
xpath的下表从1开始 python的从0开始

所有的itim用同一个管道
item交给管道
request交给调度器

=========== 获取setting中的内容
1 from 项目名.setting import ...
2 self.setting['xxx'] / self.setting.get('xxx','可以传值?')  self表示爬虫[spider]实例
3 在pipleLine中 spider.setting.get('xxx')
    中的open_spider() 在爬虫开启的时候执行一次 在里面设置的spider.xxx 可以在spider中通过self.xxx进行访问

=========== 登陆相关
一次登陆后
setting中的COOKIES_ENABLED = True 默认会带着上次请求的cookie
start_url的请求是在 start_request中进行处理最终调用Request模块进行处理 --->自定义处理[自定义start_request--自定义解析函数]
C:\xxm\learn\python_workspace\scrapy_learn\venv
=========== 分布式爬虫 scrapy_redis
在scrapy上实现了更多：
    request去重[增量式去重][通过指纹去重[判断指纹是否在redis中存在]]
    爬虫持久化
    实现分布式
